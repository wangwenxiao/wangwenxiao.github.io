---
layout: home
profile_picture:
  src: /assets/img/wwx.jpeg
  alt: website picture
---


Hi! I am Wenxiao Wang (汪文潇), a 2nd-year CS Ph.D. student at University of Maryland, working with Prof. [Soheil Feizi](https://www.cs.umd.edu/~sfeizi/). I received my B.S. degree in Computer Science from [Yao Class](https://iiis.tsinghua.edu.cn/en/yaoclass/), Tsinghua University in 2020.

I am now a research intern at Sony AI for summer 2023. I was a research intern at Bytedance (summer 2022); a research assistant at IIIS, Tsinghua University (2020-2021), working with Prof. [Hang Zhao](https://hangzhaomit.github.io) in his [MARS Lab](http://group.iiis.tsinghua.edu.cn/~marslab/#/); a visiting student researcher at UC Berkeley (2019), working with Dr. [Xinyun Chen](https://jungyhuk.github.io), Prof. [Ruoxi Jia](https://ruoxijia.info) and Prof. [Dawn Song](https://people.eecs.berkeley.edu/~dawnsong/); an intern in Bytedance AI Lab (2018), working with Dr. Yi He and Prof. [Lei Li](https://sites.cs.ucsb.edu/~lilei/).

## Preprints
**On Practical Aspects of Aggregation Defenses against Data Poisoning Attacks**  
**<u>Wenxiao Wang</u>** and Soheil Feizi  
[[arxiv]](https://arxiv.org/abs/2306.16415)

**Can AI-Generated Text be Reliably Detected?**  
Vinu Sankar Sadasivan, Aounon Kumar, Sriram Balasubramanian, **<u>Wenxiao Wang</u>** and Soheil Feizi  
[[arxiv]](https://arxiv.org/abs/2303.11156)

Media Coverage: 
[[Washington Post]](https://www.washingtonpost.com/technology/2023/06/02/turnitin-ai-cheating-detector-accuracy/)
[[UMD Science]](https://cmns.umd.edu/news-events/news/ai-generated-content-actually-detectable)
[[New Scientist]](https://www.newscientist.com/article/2366824-reliably-detecting-ai-generated-text-is-mathematically-impossible/)
[[The Register]](https://www.theregister.com/2023/03/21/detecting_ai_generated_text/?utm_source=twitter&utm_medium=twitter&utm_campaign=auto&utm_content=article)
[[TechSpot]](https://www.techspot.com/news/98031-reliable-detection-ai-generated-text-impossible-new-study.html)

**Temporal Robustness against Data Poisoning**  
**<u>Wenxiao Wang</u>** and Soheil Feizi  
[[arxiv]](https://arxiv.org/abs/2302.03684)

**Spuriosity Rankings: Sorting Data for Spurious Correlation Robustness**  
Mazda Moayeri, **<u>Wenxiao Wang</u>**, Sahil Singla and Soheil Feizi  
[[arxiv]](https://arxiv.org/abs/2212.02648)

## Publications
**Lethal Dose Conjecture on Data Poisoning**  
**<u>Wenxiao Wang</u>**, Alexander Levine and Soheil Feizi  
Conference on Neural Information Processing Systems (**NeurIPS**), 2022.  
[[paper]](https://arxiv.org/abs/2208.03309) [[code]](https://github.com/wangwenxiao/FiniteAggregation)

**Improved Certified Defenses against Data Poisoning with (Deterministic) Finite Aggregation**  
**<u>Wenxiao Wang</u>**, Alexander Levine and Soheil Feizi  
International Conference on Machine Learning (**ICML**), 2022.  
[[paper]](https://proceedings.mlr.press/v162/wang22m.html) [[code]](https://github.com/wangwenxiao/FiniteAggregation)  

**On Feature Decorrelation in Self-Supervised Learning**  
Tianyu Hua\*, **<u>Wenxiao Wang</u>**\*, Zihui Xue, Sucheng Ren, Yue Wang, Hang Zhao (\*equal contribution)  
International Conference on Computer Vision (**ICCV**), 2021. [**oral**]  
[[paper]](https://openaccess.thecvf.com/content/ICCV2021/html/Hua_On_Feature_Decorrelation_in_Self-Supervised_Learning_ICCV_2021_paper.html) [[code]](https://github.com/PatrickHua/FeatureDecorrelationSSL)  

**DPlis: Boosting Utility of Differentially Private Deep Learning via Randomized Smoothing**  
**<u>Wenxiao Wang</u>**, Tianhao Wang, Lun Wang, Nanqing Luo, Pan Zhou, Dawn Song, Ruoxi Jia  
Privacy Enhancing Technologies Symposium (**PETS**), 2021.  
[[paper]](https://www.petsymposium.org/2021/files/papers/issue4/popets-2021-0065.pdf) [[code]](https://github.com/wangwenxiao/DPlis)

**REFIT: A Unified Watermark Removal Framework For Deep Learning Systems With Limited Data**  
Xinyun Chen\*, **<u>Wenxiao Wang</u>**\*, Yiming Ding, Chris Bender, Ruoxi Jia, Bo Li, Dawn Song (\*equal contribution)  
ACM Asia Conference on Computer and Communications Security (**AsiaCCS**), 2021.  
[[paper]](https://dl.acm.org/doi/abs/10.1145/3433210.3453079) [[code]](https://github.com/sunblaze-ucb/REFIT)

**The Secret Revealer: Generative Model Inversion Attacks Against Deep Neural Networks**  
Yuheng Zhang\*, Ruoxi Jia\*, Hengzhi Pei, **<u>Wenxiao Wang</u>**, Bo Li, Dawn Song (\*equal contribution)  
Conference on Computer Vision and Pattern Recognition (**CVPR**), 2020. [**oral**]  
[[paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Zhang_The_Secret_Revealer_Generative_Model-Inversion_Attacks_Against_Deep_Neural_Networks_CVPR_2020_paper.html) [[code]](https://github.com/AI-secure/GMI-Attack)

**Leveraging Unlabeled Data for Watermark Removal of Deep Neural Networks**  
Xinyun Chen\*, **<u>Wenxiao Wang</u>**\*, Yiming Ding, Chris Bender, Ruoxi Jia, Bo Li, Dawn Song (\*equal contribution)  
ICML Workshop on Security and Privacy of Machine Learning, 2019.  
[[paper]](https://wangwenxiao.github.io/files/watermark_removal_icml19_workshop.pdf)

## Talks
- **Lethal Dose Conjecture: From Few-shot Learning to Potentially Nearly Optimal Defenses
against Data Poisoning**, TMLR Group, Hong Kong Baptist University, December 2022.

## Services
Program Committee / Reviewer of:
- TPAMI
- NeurIPS 2022, 2023
- ICML 2022, 2023 (Outstanding Reviewer in 2022)
- Workshop on Adversarial Robustness In the Real World (ECCV 2022,ICCV 2021)
- Workshop on Socially Responsible Machine Learning (ICML 2021)
- Workshop on Adversarial Machine Learning in Real-World Computer Vision Systems and Online Challenges (CVPR 2021)
- Workshop on Security and Safety in Machine Learning Systems (ICLR 2021)
